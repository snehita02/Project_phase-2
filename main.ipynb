{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330837ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array   \n",
    "\n",
    "from keras import losses \n",
    "from keras import optimizers \n",
    "from keras import metrics \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw \n",
    "import cv2\n",
    "import pyttsx3 as p \n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af883fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "\t\tself.xmin = xmin\n",
    "\t\tself.ymin = ymin\n",
    "\t\tself.xmax = xmax\n",
    "\t\tself.ymax = ymax\n",
    "\t\tself.objness = objness\n",
    "\t\tself.classes = classes\n",
    "\t\tself.label = -1\n",
    "\t\tself.score = -1\n",
    "\n",
    "\tdef get_label(self):\n",
    "\t\tif self.label == -1:\n",
    "\t\t\tself.label = np.argmax(self.classes)\n",
    "\n",
    "\t\treturn self.label\n",
    "\n",
    "\tdef get_score(self):\n",
    "\t\tif self.score == -1:\n",
    "\t\t\tself.score = self.classes[self.get_label()]\n",
    "\t\treturn self.score\n",
    "    \n",
    "def _sigmoid(x):\n",
    "\treturn 1. / (1. + np.exp(-x))\n",
    "    \n",
    "    \n",
    "\n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "\tgrid_h, grid_w = netout.shape[:2] \n",
    "\tnb_box = 3 \n",
    "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1)) \n",
    "\tnb_class = netout.shape[-1] - 5\n",
    "\tboxes = []\n",
    "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\tfor i in range(grid_h*grid_w):\n",
    "\t\trow = i / grid_w\n",
    "\t\tcol = i % grid_w\n",
    "\t\tfor b in range(nb_box):\n",
    "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
    "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
    "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "\t\t\tx = (col + x) / grid_w \n",
    "\t\t\ty = (row + y) / grid_h \n",
    "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w \n",
    "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h \n",
    "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
    "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "\t\t\tboxes.append(box)\n",
    "\treturn boxes    \n",
    "\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "\tnew_w, new_h = net_w, net_h\n",
    "\tfor i in range(len(boxes)):\n",
    "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "    \n",
    "    \n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "\tx1, x2 = interval_a\n",
    "\tx3, x4 = interval_b\n",
    "\tif x3 < x1:\n",
    "\t\tif x4 < x1:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x1\n",
    "\telse:\n",
    "\t\tif x2 < x3:\n",
    "\t\t\t return 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x3 \n",
    "\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\tintersect = intersect_w * intersect_h\n",
    "    \n",
    "    \n",
    "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin  \n",
    "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\tunion = w1*h1 + w2*h2 - intersect\n",
    "\treturn float(intersect) / union\n",
    "\n",
    "def do_nms(boxes, nms_thresh):   \n",
    "\tif len(boxes) > 0:\n",
    "\t\tnb_class = len(boxes[0].classes)\n",
    "\telse:\n",
    "\t\treturn\n",
    "\tfor c in range(nb_class):\n",
    "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\t\tfor i in range(len(sorted_indices)):\n",
    "\t\t\tindex_i = sorted_indices[i]\n",
    "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
    "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
    "\t\t\t\tindex_j = sorted_indices[j]\n",
    "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "\t\t\t\t\tboxes[index_j].classes[c] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796f7119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "\timage = load_img(filename)\n",
    "\twidth, height = image.size\n",
    "\timage = load_img(filename, target_size=shape) \n",
    "\timage = img_to_array(image)\n",
    "\timage = image.astype('float32')\n",
    "\timage /= 255.0 \n",
    "\timage = expand_dims(image, 0)\n",
    "\treturn image, width, height\n",
    "    \n",
    "    \n",
    "\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
    "\tfor box in boxes:\n",
    "\t\tfor i in range(len(labels)):\n",
    "\t\t\tif box.classes[i] > thresh:\n",
    "\t\t\t\tv_boxes.append(box)\n",
    "\t\t\t\tv_labels.append(labels[i])\n",
    "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
    "\treturn v_boxes, v_labels, v_scores   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efea3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "# \tdata = pyplot.imread(filename)\n",
    "# \tpyplot.imshow(data)\n",
    "# \tax = pyplot.gca()\n",
    "# \tfor i in range(len(v_boxes)):\n",
    "# \t\tbox = v_boxes[i]\n",
    "# \t\t# get coordinates\n",
    "# \t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "# \t\twidth, height = x2 - x1, y2 - y1\n",
    "# \t\trect = Rectangle((x1, y1), width, height, fill=False, color='white') \n",
    "# \t\tax.add_patch(rect)\n",
    "# \t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "# \t\tpyplot.text(x1, y1, label, color='white')\n",
    "# \tpyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ccb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------- distance of object  ---------------------------------------------- \n",
    "\n",
    "def dis(real_width,ref_width,width):\n",
    "    known_dis = 45 \n",
    "    focal_length = (known_dis * real_width ) / ref_width\n",
    "    distance = (focal_length * real_width ) / width\n",
    "    return distance\n",
    "\n",
    "\n",
    "# -------------------------------------------- voice output ---------------------------------------------- \n",
    "\n",
    "def speak(txt):\n",
    "    speak = p.init()\n",
    "    speak.say(txt)\n",
    "    speak.runAndWait()  \n",
    "\n",
    "def talk(view):\n",
    "    for k,v in view.items():\n",
    "        if len(v) != 0:\n",
    "            for k1,v1 in v.items():\n",
    "                if k == 'front':\n",
    "                    if len(v1) == 1: \n",
    "                        txt = 'one ' + k1 + ' are in ' + k + ' of you ' + str(min(v1)) + ' meters'\n",
    "                        speak(txt)  \n",
    "                    else:\n",
    "                        txt = str(len(v1)) + ' ' + k1 + 's are in ' + k + ' of you '  + str(min(v1)) + ' meters'\n",
    "                        speak(txt) \n",
    "                else:\n",
    "                    if len(v1) == 1: \n",
    "                        txt = 'one ' + k1 + ' is in ' + k + ' side'+ ' from you '  + str(min(v1)) + ' meters'\n",
    "                        speak(txt)\n",
    "                    else:\n",
    "                        txt = str(len(v1)) + ' ' + k1 + 's are in ' + k  + ' side'+ ' from you '  + str(min(v1)) + ' meters'\n",
    "                        speak(txt) \n",
    "\n",
    "\n",
    "# --------------------------------------- direction dictionary ------------------------------------------\n",
    "\n",
    "def check(x,y,w,view,display,label,real_width,ref_width):\n",
    "    mid_point = x + w // 2\n",
    "    if (x + w) < display['left'][1] :\n",
    "        if label not in view['left'].keys(): \n",
    "            view['left'][label] = [] \n",
    "        view['left'][label].append(round(dis(real_width[label],ref_width[label],w)*10,2)) \n",
    "        return \n",
    "    if x > display['right'][0]:  \n",
    "        if label not in view['right'].keys(): \n",
    "            view['right'][label] = []\n",
    "        view['right'][label].append(round(dis(real_width[label],ref_width[label],w)*10,2))\n",
    "        return \n",
    "    for k,v in display.items():\n",
    "        if v[0] <= mid_point and mid_point <= v[1]:\n",
    "            if label not in view[k].keys(): \n",
    "                view[k][label] = []\n",
    "            view[k][label].append(round(dis(real_width[label],ref_width[label],w)*10,2))\n",
    "            return \n",
    "    if mid_point < display['left'][0]:\n",
    "        if label not in view['left'].keys(): \n",
    "            view['left'][label] = []\n",
    "        view['left'][label].append(round(dis(real_width[label],ref_width[label],w)*10,2))\n",
    "        return \n",
    "    if label not in view['right'].keys(): \n",
    "        view['right'][label] = []\n",
    "    view['right'][label].append(round(dis(real_width[label],ref_width[label],w)*10,2)) \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e4ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- distance estimation varaibles ---------------------------------------\n",
    "\n",
    "real_width = {\"person\" : 16, \"bicycle\" : 66, \"car\" : 109, \"motorbike\" : 57, \"aeroplane\" : 590, \"bus\": 472 , \"train\": 529 , \"truck\" : 496,\n",
    "        \"boat\": 120 , \"traffic light\" : 11, \"fire hydrant\": 12  , \"stop sign\" : 20 , \"parking meter\": 177 , \"bench\":48 ,\n",
    "        \"bird\":9 , \"cat\":15 , \"dog\":25 , \"horse\": 35 , \"sheep\": 27 , \"cow\": 35 , \"elephant\": 145 , \"bear\": 96, \"zebra\":96 , \"giraffe\":192 ,\n",
    "        \"backpack\":12 , \"umbrella\":51 , \"handbag\":9 , \"tie\": 3 , \"suitcase\":20 , \"frisbee\":3937  , \"skis\":70 , \"snowboard\":63 ,\n",
    "        \"sports ball\":9 , \"kite\":9 , \"baseball bat\":34 , \"baseball glove\":13 , \"skateboard\":9 , \"surfboard\":77 ,\n",
    "        \"tennis racket\":27 , \"bottle\":3 , \"wine glass\":3 , \"cup\":4 , \"fork\":6 , \"knife\":8 , \"spoon\":6 , \"bowl\":5 , \"banana\":6 ,\n",
    "        \"apple\":3 , \"sandwich\":4 , \"orange\":3 , \"broccoli\":4 , \"carrot\":5 , \"hot dog\":6 , \"pizza\":8 , \"donut\":5 , \"cake\":10 ,\n",
    "        \"chair\":17 , \"sofa\":77 , \"pottedplant\":9 , \"bed\":85 , \"diningtable\":50 , \"toilet\":16 , \"tvmonitor\":32 , \"laptop\":15 , \"mouse\":4 ,\n",
    "        \"remote\":6 , \"keyboard\":15 , \"cell phone\":5 , \"microwave\":14 , \"oven\":17 , \"toaster\":8 , \"sink\":19 , \"refrigerator\":23 ,\n",
    "        \"book\":11 , \"clock\":12 , \"vase\":9 , \"scissors\":7 , \"teddy bear\":15 , \"hair drier\":12 , \"toothbrush\":7 }  \n",
    "\n",
    "ref_width =   {'person': 179, 'bicycle': 387, 'car': 334, 'motorbike': 395, 'aeroplane': 296, 'bus': 283, 'train': 290, 'truck': 329, 'boat': 230,\n",
    "           'traffic light': 349, 'fire hydrant': 389, 'stop sign': 191, 'parking meter': 382, 'bench': 342, 'bird': 315, 'cat': 341\n",
    "           , 'dog': 242, 'horse': 386, 'sheep': 377, 'cow': 339, 'elephant': 329, 'bear': 270, 'zebra': 385,\n",
    "           'giraffe': 211, 'backpack': 335, 'umbrella': 387, 'handbag': 285, 'tie': 374, \n",
    "           'suitcase': 170, 'frisbee': 303, 'skis': 174, 'snowboard': 128, 'sports ball': 361, 'kite': 338, 'baseball bat': 300,\n",
    "           'baseball glove': 160, 'skateboard': 378, 'surfboard': 229, 'tennis racket': 417, 'bottle': 70, 'wine glass': 256,\n",
    "           'cup': 255, 'fork': 315, 'knife': 395, 'spoon': 379, 'bowl': 376, 'banana': 356, 'apple': 272, 'sandwich': 322,\n",
    "           'orange': 295, 'broccoli': 261, 'carrot': 243, 'hot dog': 379, 'pizza': 388, 'donut': 342, 'cake': 378, \n",
    "           'chair': 258, 'sofa': 336, 'pottedplant': 407, 'bed': 394, 'diningtable': 350, 'toilet': 292, \n",
    "           'tvmonitor': 375, 'laptop': 378, 'mouse': 275, 'remote': 434, 'keyboard': 180, 'cell phone': 256, \n",
    "           'microwave': 367, 'oven': 417, 'toaster': 136, 'sink': 120, 'refrigerator': 257, 'book': 462, \n",
    "           'clock': 299, 'vase': 157, 'scissors': 379, 'teddy bear': 273, 'hair drier': 109, 'toothbrush': 412}\n",
    "\n",
    "\n",
    "# --------------------------------------- drawing rectangle in cv2 ---------------------------------------\n",
    "    \n",
    "def cvdraw(photo_filename, v_boxes, v_labels, v_scores,detection,obj_name):  \n",
    "    img=cv2.imread(photo_filename) \n",
    "    direction = ''\n",
    "    height,width,channels = img.shape\n",
    "    image_size = width\n",
    "    ratio = '1:2:1'\n",
    "    ratio_list = list(map(int,ratio.split(':'))) \n",
    "    parts = sum(ratio_list)\n",
    "    one_part = image_size // parts \n",
    "    l = ratio_list[0] * one_part \n",
    "    f = ratio_list[1] * one_part \n",
    "    r =  ratio_list[2] * one_part  \n",
    "    display = {\n",
    "    'left'  : [0 , l],\n",
    "    'front' : [l + 1 , f + l] , \n",
    "    'right' : [f + l + 1 , image_size]  \n",
    "    } \n",
    "    view = {\n",
    "        'left' :dict(),\n",
    "        'front':dict(),\n",
    "        'right':dict()\n",
    "    }\n",
    "    count = 0 \n",
    "    op = []\n",
    "    for i in range(len(v_boxes)):\n",
    "        count += 1 \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        org = (50, 50)\n",
    "        fontScale = 0.4\n",
    "        color = (0, 0, 0) \n",
    "        thickness = 1\n",
    "        x = v_boxes[i].xmin \n",
    "        y = v_boxes[i].ymin\n",
    "        w = v_boxes[i].xmax\n",
    "        h = v_boxes[i].ymax  \n",
    "        op.append([x,y,w])\n",
    "        \n",
    "        check(x,y,w,view,display,v_labels[i],real_width,ref_width)  \n",
    "        \n",
    "        confi = str(round(v_scores[i],2)/100) \n",
    "        confi = confi[0:4]\n",
    "        text_size, _ = cv2.getTextSize(v_labels[i] + '  ' +confi, font, fontScale,thickness)\n",
    "        text_w, text_h = text_size \n",
    "        cv2.rectangle(img, (x,y) , (x + text_w + 5, y - text_h - 5), (0,255,0) , -1)\n",
    "        cv2.rectangle(img, (x, y), (w, h),color=(0, 255, 0), thickness=2)\n",
    "        cv2.putText(img, v_labels[i] + '  ' +confi,(x+2,y-2), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "#     for k,v in view.items():\n",
    "#         for k1,v1 in v.items():\n",
    "#             print(k,k1,v1)\n",
    "#     print(\"total detections : \",count) \n",
    "#     print(op)   \n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = (50, 50)\n",
    "    fontScale = 0.3\n",
    "    color = (0, 0, 0) \n",
    "    thickness = 1\n",
    "#     print('detection : ',detection)\n",
    "    if detection:\n",
    "        temp = 'Finding '+obj_name+' ...'\n",
    "        text_size, _ = cv2.getTextSize(temp + '  ', font, fontScale,thickness) \n",
    "        text_w, text_h = text_size \n",
    "        cv2.rectangle(img, (5,15) , (5 + text_w + 5, 15 - text_h - 5), (0,255,0) , -1)    \n",
    "        cv2.putText(img,temp,(5+2,15-2),font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    else:\n",
    "        temp = 'Detecting ...'\n",
    "        text_size, _ = cv2.getTextSize(temp + '  ', font, fontScale,thickness) \n",
    "        text_w, text_h = text_size \n",
    "        cv2.rectangle(img, (5,15) , (5 + text_w + 5, 15 - text_h - 5), (0,255,0) , -1)    \n",
    "        cv2.putText(img,temp,(5+2,15-2),font, fontScale, color, thickness, cv2.LINE_AA)  \n",
    "        \n",
    "    cv2.imshow(temp,img)\n",
    "        \n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows() \n",
    "#     talk(view) \n",
    "    if len(v_boxes) != 0:  \n",
    "        p2 = Thread(target = talk , args = (view,))\n",
    "        p2.start()\n",
    "    elif detection == True and len(v_boxes) == 0:      \n",
    "        speak('No objects found')  \n",
    "    else: \n",
    "        speak('You can walk freely now')   \n",
    "#     if cv2.waitKey(48) == ord('q'): \n",
    "#     cv2.waitKey(0)   \n",
    "#     cv2.destroyAllWindows() \n",
    "#     return w \n",
    "\n",
    "# --------------------------------------- drawing rectangle in pillow --------------------------------------- \n",
    "# def cvdraw(photo_filename, v_boxes, v_labels, v_scores):\n",
    "#     image = Image.open(photo_filename)\n",
    "#     for i in range(len(v_boxes)):\n",
    "#         x = v_boxes[i].xmin\n",
    "#         y = v_boxes[i].ymin\n",
    "#         w = v_boxes[i].xmax\n",
    "#         h = v_boxes[i].ymax \n",
    "#         draw = ImageDraw.Draw(image) \n",
    "#         left = (x,y)\n",
    "#         right = (w,h) \n",
    "#         position = (x+3,y+3)\n",
    "#         text = v_labels[i] + '  ' +str(round(v_scores[i],2) )\n",
    "#         bbox = draw.textbbox(position, text ) \n",
    "#         draw.rectangle(bbox, fill=(0,255,0))\n",
    "#         draw.text(position, text,  fill=\"black\") \n",
    "#         draw.rectangle((left,right),outline=(0,255,0),width=3) \n",
    "#     image.show()\n",
    "#     image.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "797e7c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "model = load_model('model.h5')\n",
    "model.compile(loss = 'mean_squared_error',optimizer = 'sgd', metrics = [metrics.categorical_accuracy]) \n",
    "def image_detection(photo_filename,obj_name='none'):   \n",
    "#     photo_filename = cv2.resize(photo_filename,(416,416))\n",
    "    input_w, input_h = 416, 416   \n",
    "    input_w, input_h = 416, 416 \n",
    "    image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
    "    yhat = model.predict(image) \n",
    "    anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]  \n",
    "    class_threshold = 0.6\n",
    "    boxes = list()\n",
    "    for i in range(len(yhat)):\n",
    "        boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
    "    correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "    do_nms(boxes, 0.5)      \n",
    "    labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "        \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "        \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "        \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "        \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "        \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "        \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "        \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "        \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "        \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]  \n",
    "    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)  \n",
    "    total_detection = len(v_labels) \n",
    "#     for i in range(total_detection):\n",
    "#         print(v_boxes[i])\n",
    "#         print(v_labels[i])\n",
    "#         print(v_scores[i])\n",
    "    r_boxes = []\n",
    "    r_labels = []\n",
    "    r_scores = []\n",
    "    detection = False\n",
    "    if obj_name != 'none':\n",
    "        detection = True\n",
    "        for i in range(total_detection): \n",
    "            if v_labels[i] == obj_name:  \n",
    "                r_boxes.append(v_boxes[i])\n",
    "                r_labels.append(v_labels[i]) \n",
    "                r_scores.append(v_scores[i])   \n",
    "    else:  \n",
    "        r_boxes = v_boxes.copy()     \n",
    "        r_labels = v_labels.copy()   \n",
    "        r_scores = v_scores.copy()   \n",
    "#     print(r_boxes)                       \n",
    "#     print(r_labels)                       \n",
    "#     print(r_scores)                      \n",
    "            \n",
    "    cvdraw(photo_filename, r_boxes, r_labels, r_scores,detection,obj_name)   \n",
    "#     cvdraw(photo_filename, v_boxes, v_labels, v_scores)         \n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "import os     \n",
    "import cv2 \n",
    "import speech_recognition as sr\n",
    "import pyttsx3 \n",
    "from threading import Thread \n",
    "\n",
    "\n",
    "\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "        \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "        \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "        \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "        \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "        \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "        \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "        \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "        \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "        \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9512817",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer() \n",
    "\n",
    "cmd = '' \n",
    "flag = True \n",
    "def mic():  \n",
    "    global cmd,flag\n",
    "    while flag:   \n",
    "        print('Entered mic function ....')  \n",
    "        try:\n",
    "            with sr.Microphone() as source2:\n",
    "#                 r.adjust_for_ambient_noise(source2, duration=0.2)\n",
    "#                 audio2 = r.listen(source2)\n",
    "#                 MyText = r.recognize_google(audio2)\n",
    "#                 MyText = MyText.lower()\n",
    "#                 cmd = MyText \n",
    "\n",
    "                r.adjust_for_ambient_noise(source2, duration=0.2)\n",
    "                audio2 = r.listen(source2)\n",
    "                MyText = r.recognize_google(audio2)\n",
    "                MyText = MyText.lower()\n",
    "                names = list(MyText.split()) \n",
    "                cmd = names\n",
    "                print(cmd)  \n",
    "                if 'stop' in cmd:\n",
    "                    flag = False \n",
    "                    break\n",
    "                print(MyText)   \n",
    "        except sr.RequestError as e:\n",
    "            print(\"Could not request results; {0}\".format(e))\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"unknown error occurred\")\n",
    "            \n",
    "\n",
    "def start_detection(finding = False,obj_name = 'none',start_find = False):    \n",
    "    video = cv2.VideoCapture(0)\n",
    "    # video = cv2.VideoCapture('sample.mp4')  \n",
    "    count = 0  \n",
    "    condition = False \n",
    "    global cmd,flag \n",
    "    flag = True\n",
    "    cmd = []\n",
    "    if finding == False: \n",
    "        while True:  \n",
    "            ret , frame = video.read()      \n",
    "            if ret == True:  \n",
    "                count += 1 \n",
    "                size = (416,416) \n",
    "                frame = cv2.resize(frame,size)          \n",
    "                if count % 48 == 0:                                                          \n",
    "                    name = 'frame {} in {} sec.png'.format((count//5),count//32)  \n",
    "                    cv2.imwrite(name,frame)\n",
    "                    print('Entered start_detection function .....')   \n",
    "                    image_detection(name)  \n",
    "                    t = threading.Thread(target=mic) \n",
    "                    t.start()  \n",
    "                    if 'find' in cmd:  \n",
    "                        found = False \n",
    "                        obj_name = 'none'\n",
    "                        for i in cmd:\n",
    "                            if i in labels: \n",
    "                                found = True\n",
    "                                obj_name = i \n",
    "                                break \n",
    "                        cmd.clear()\n",
    "                        if obj_name == 'none':\n",
    "                            speak('cant detect object')\n",
    "                        else:\n",
    "#                             video.release()    \n",
    "#                             cv2.destroyAllWindows()   \n",
    "                            temp = 'finding '+obj_name\n",
    "#                             speak(temp) \n",
    "                            pr = threading.Thread(target=speak,args=(temp,))  \n",
    "                            pr.start() \n",
    "                            condition = True\n",
    "                            start_detection(True,obj_name,True) \n",
    "                            cmd.clear()\n",
    "            \n",
    "        #             p1 = Thread(target = image_detection , agrs = (name,) )\n",
    "        #             p1.start() \n",
    "                    try:\n",
    "                        os.remove(name)\n",
    "                    except:\n",
    "                        pass \n",
    "            if cv2.waitKey(1) == ord('q') or 'stop' in cmd: \n",
    "                flag = False\n",
    "                cmd.clear()\n",
    "                break\n",
    "        video.release()    \n",
    "        cv2.destroyAllWindows()   \n",
    "    else:\n",
    "        while True:       \n",
    "            ret , frame = video.read()\n",
    "            if ret == True:  \n",
    "                count += 1 \n",
    "                size = (416,416)\n",
    "                frame = cv2.resize(frame,size)          \n",
    "                if count % 48 == 0:                                                          \n",
    "                    name = 'frame {} in {} sec.png'.format((count//5),count//32) \n",
    "                    cv2.imwrite(name,frame)\n",
    "                    image_detection(name,obj_name)   \n",
    "                    t = threading.Thread(target=mic) \n",
    "                    t.start()  \n",
    "#                     t = threading.Thread(target=mic) \n",
    "#                     t.start() \n",
    "        #             p1 = Thread(target = image_detection , agrs = (name,) )\n",
    "        #             p1.start() \n",
    "                    os.remove(name) \n",
    "            if cv2.waitKey(1) == ord('q') or 'stop' in cmd: \n",
    "                flag = False\n",
    "                cmd.clear() \n",
    "                if start_find:\n",
    "                    flag = True \n",
    "                break \n",
    "        video.release()    \n",
    "        cv2.destroyAllWindows()  \n",
    "    return condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffab06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ebfddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3 \n",
    "import threading \n",
    "r = sr.Recognizer()\n",
    "\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "        \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "        \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "        \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "        \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "        \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "        \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "        \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "        \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "        \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]  \n",
    "\n",
    "def main():\n",
    "    while(1): \n",
    "        print('Entered main function .....') \n",
    "        try:\n",
    "            with sr.Microphone() as source2:\n",
    "                r.adjust_for_ambient_noise(source2, duration=0.2)\n",
    "                audio2 = r.listen(source2)\n",
    "                MyText = r.recognize_google(audio2)\n",
    "                MyText = MyText.lower()\n",
    "                names = list(MyText.split())  \n",
    "                print(names) \n",
    "                print(\"Did you say \",MyText) \n",
    "                if 'start' in MyText:\n",
    "                    speak('detecting') \n",
    "                    condition = start_detection()  \n",
    "                    if condition:\n",
    "                        start_detection()\n",
    "#                     t1 = threading.Thread(target=start_detection)\n",
    "#                     t2 = threading.Thread(target=mic) \n",
    "\n",
    "#                     t1.start()\n",
    "#                     t2.start()\n",
    "\n",
    "#                     t1.join()\n",
    "#                     t2.join()  \n",
    "                elif 'find' in MyText: \n",
    "                    found = False \n",
    "                    obj_name = 'none'\n",
    "                    for i in names:\n",
    "                        if i in labels: \n",
    "                            found = True\n",
    "                            obj_name = i \n",
    "                            break \n",
    "                    if obj_name == 'none':\n",
    "                        speak('cant detect object')\n",
    "                    else:\n",
    "                        temp = 'finding '+obj_name\n",
    "                        speak(temp) \n",
    "                        start_detection(True,obj_name)  \n",
    "                elif 'stop' in MyText:\n",
    "                    break\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Could not request results; {0}\".format(e))\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"unknown error occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd3eedec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered main function .....\n",
      "['start', 'detection']\n",
      "Did you say  start detection\n",
      "Entered start_detection function .....\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Entered mic function ....\n",
      "Entered start_detection function .....\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "['stop', 'detection']\n",
      "Entered main function .....\n",
      "['start', 'detection']\n",
      "Did you say  start detection\n",
      "Entered start_detection function .....\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "Entered mic function ....\n",
      "Entered start_detection function .....\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "['find', 'car']\n",
      "find car\n",
      "Entered mic function ....\n",
      "Entered mic function ....\n",
      "unknown error occurred\n",
      "Entered mic function ....\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "unknown error occurred\n",
      "Entered mic function ....\n",
      "Entered mic function ....\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "Entered mic function ....\n",
      "['stop', 'detection']\n",
      "['stop', 'detection']\n",
      "['stop', 'detection']\n",
      "Entered start_detection function .....\n",
      "1/1 [==============================] - 0s 463ms/step\n",
      "unknown error occurred\n",
      "Entered mic function ....\n",
      "Entered mic function ....\n",
      "Entered start_detection function .....\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "Entered mic function ....\n",
      "Entered start_detection function .....\n",
      "1/1 [==============================] - 1s 515ms/step\n",
      "Entered mic function ....\n",
      "Entered start_detection function .....\n",
      "1/1 [==============================] - 0s 492ms/step\n",
      "Entered mic function ....\n",
      "Entered start_detection function .....\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "['stop', 'detection']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-39:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\battu\\anaconda3\\envs\\Project\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\battu\\anaconda3\\envs\\Project\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\battu\\AppData\\Local\\Temp\\ipykernel_2516\\370644702.py\", line 24, in talk\n",
      "  File \"C:\\Users\\battu\\AppData\\Local\\Temp\\ipykernel_2516\\370644702.py\", line 15, in speak\n",
      "  File \"C:\\Users\\battu\\anaconda3\\envs\\Project\\lib\\site-packages\\pyttsx3\\engine.py\", line 177, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered main function .....\n",
      "['stop', 'detection']\n",
      "['stop', 'detection']\n",
      "['stop', 'deduction', 'stop', 'detection']\n",
      "['stop', 'deduction', 'stop', 'detection']\n",
      "unknown error occurred\n",
      "Entered main function .....\n",
      "['find', 'car']\n",
      "Did you say  find car\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "Entered mic function ....\n",
      "1/1 [==============================] - 0s 439ms/step\n",
      "unknown error occurred\n",
      "Entered mic function ....\n",
      "Entered mic function ....\n",
      "1/1 [==============================] - 0s 443ms/step\n",
      "Entered mic function ....\n",
      "1/1 [==============================] - 0s 472ms/step\n",
      "unknown error occurred\n",
      "Entered mic function ....\n",
      "unknown error occurred\n",
      "Entered mic function ....\n",
      "Entered mic function ....\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "['architecture']\n",
      "architecture\n",
      "Entered mic function ....\n",
      "Entered mic function ....\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "['stop', 'detection']\n",
      "['stop', 'detection']\n",
      "Entered main function .....\n",
      "['stop', 'detection']\n",
      "['stop', 'detection']\n",
      "['stop', 'detection']\n",
      "unknown error occurred\n",
      "Entered main function .....\n",
      "['stop', 'detection']\n",
      "Did you say  stop detection\n"
     ]
    }
   ],
   "source": [
    "main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
